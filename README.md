# Speech-Emotions-Recognition-System
**Jamia Hamdard University B.Tech Minor Project in Speech Emotions Recognition System using Deep Learning**

<h1 align="left">SPEECH EMOTION RECOGNITION SYSTEM</h1>
Through all the available senses humans can actually sense the emotional state of their communication partner. The emotional detection is natural for humans but it is very difficult task for computers; although they can easily understand content based information, accessing the depth behind content is difficult and thatâ€™s what speech emotion recognition (SER) sets out to do. It is a system through which various audio speech files are classified into different emotions such as happy, sad, anger and neutral by computer. SER can be used in areas such as the medical field or customer call centers.


<h2 align="left">DATASET</h2>
The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) Dataset from Kaggle contains 1440 audio files from 24 Actors vocalizing two lexically-matched statements. Emotions include angry, happy, sad, fearful, calm, neutral, disgust, and surprised.[Dataset].(https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio)

<h2 align="left">STEPS</h2>

1 - IMPORT DEPENDENCIES LIBRARIES
2 - LOAD THE RAVDESS DATASET
3 - USING SPEECH RECOGNITION API TO CONVERT AUDIO TO TEXT
4 - PLOTTING visuals TO UNDERSTAND RAW AUDIO FILES
5 - CLEANING & MASKING
6 - FEATURE EXTRACTION
7 - LABELS CLASSIFICATION
8 - LOADING OF DATA & SPLITTING OF DATASET
9 - APPLY MLP CLASSIFIER
10 - SAVING THE MODEL
